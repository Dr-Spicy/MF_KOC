{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbf04df9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77b41847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2025/04/03 \n",
    "import os\n",
    "import re\n",
    "import emoji\n",
    "from zhon.hanzi import punctuation as cn_punc\n",
    "import json\n",
    "import glob\n",
    "from langid import classify\n",
    "import jieba \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c8cddd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5f43e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Han\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.738 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the MeetFresh user dictionary\n",
    "jieba.load_userdict(\"MF_dict.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the constants\n",
    "\n",
    "core_keywords = {\n",
    "    '鲜芋仙', 'Meet Fresh', 'MeetFresh', '台湾美食', '甜品', \n",
    "    '芋圆', 'taro', '仙草', 'grass jelly', '奶茶', 'milk tea',\n",
    "    '豆花', 'tofu pudding', '奶刨冰', 'milked shaved ice',\n",
    "    '红豆汤', 'purple rice soup', '紫米粥', 'red bean soup',\n",
    "    '2001 Coit Rd', 'Park Pavillion Center', '(972) 596-6088'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "482d582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = pd.read_json('..\\..\\Data\\processed\\contents_cooked.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2217f541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>note_body</th>\n",
       "      <th>tag_list</th>\n",
       "      <th>image_count</th>\n",
       "      <th>content_type_video</th>\n",
       "      <th>hot_note</th>\n",
       "      <th>post_time</th>\n",
       "      <th>last_update_time</th>\n",
       "      <th>scraped_time</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>liked_count</th>\n",
       "      <th>collected_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>share_count</th>\n",
       "      <th>interaction_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67d0d605000000002903d86a</td>\n",
       "      <td>576d3bde82ec3952ff40c5e1</td>\n",
       "      <td>有没有和我一样【吃茶三千】一喝一个不吱声的</td>\n",
       "      <td>连地址都不想写了[笑哭R]\\n虽然环境还不错，颜值也不错\\n但我感觉自己完全拔草了\\n尝了m...</td>\n",
       "      <td>达拉斯网红奶茶,达拉斯奶茶,达拉斯,达拉斯生活,达拉斯美食,达拉斯周边,达拉斯探店</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-03-12 00:32:05</td>\n",
       "      <td>2025-03-12 00:32:06</td>\n",
       "      <td>2025-03-12 00:55:08</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67c8960f000000002503ff5f</td>\n",
       "      <td>576d3bde82ec3952ff40c5e1</td>\n",
       "      <td>【达拉斯·玩】超治愈系手工体验！MUMU Garden</td>\n",
       "      <td>📍301 W Parker Rd #208[话题]#, Plano, TX 75023（快乐...</td>\n",
       "      <td>208,达拉斯生活,达拉斯探店,达拉斯,达拉斯吃喝玩乐,达拉斯手工,达拉斯周末,达拉斯周边,...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-03-05 18:21:03</td>\n",
       "      <td>2025-03-05 18:21:04</td>\n",
       "      <td>2025-03-12 00:55:08</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    note_id                   user_id  \\\n",
       "0  67d0d605000000002903d86a  576d3bde82ec3952ff40c5e1   \n",
       "1  67c8960f000000002503ff5f  576d3bde82ec3952ff40c5e1   \n",
       "\n",
       "                         title  \\\n",
       "0        有没有和我一样【吃茶三千】一喝一个不吱声的   \n",
       "1  【达拉斯·玩】超治愈系手工体验！MUMU Garden   \n",
       "\n",
       "                                           note_body  \\\n",
       "0  连地址都不想写了[笑哭R]\\n虽然环境还不错，颜值也不错\\n但我感觉自己完全拔草了\\n尝了m...   \n",
       "1  📍301 W Parker Rd #208[话题]#, Plano, TX 75023（快乐...   \n",
       "\n",
       "                                            tag_list  image_count  \\\n",
       "0          达拉斯网红奶茶,达拉斯奶茶,达拉斯,达拉斯生活,达拉斯美食,达拉斯周边,达拉斯探店            1   \n",
       "1  208,达拉斯生活,达拉斯探店,达拉斯,达拉斯吃喝玩乐,达拉斯手工,达拉斯周末,达拉斯周边,...           14   \n",
       "\n",
       "   content_type_video  hot_note           post_time    last_update_time  \\\n",
       "0                   0         0 2025-03-12 00:32:05 2025-03-12 00:32:06   \n",
       "1                   0         0 2025-03-05 18:21:03 2025-03-05 18:21:04   \n",
       "\n",
       "         scraped_time  elapsed_time  liked_count  collected_count  \\\n",
       "0 2025-03-12 00:55:08             0            5                2   \n",
       "1 2025-03-12 00:55:08             6           47               23   \n",
       "\n",
       "   comment_count  share_count  interaction_count  \n",
       "0             10            3                 17  \n",
       "1              7           37                 77  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91168511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the title and note_body into a single string\n",
    "def process_text(note):\n",
    "    return note['title'] + ' ' + note['note_body']\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "cont['text'] = cont.apply(process_text, axis=1).astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a9a6012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "note_id                                        6722d61c000000001a01e79f\n",
       "user_id                                        576d3bde82ec3952ff40c5e1\n",
       "title                                            【达拉斯·吃】刘一手，目前火锅届性价比天花板\n",
       "note_body             📍2001 Coit Rd Ste 137D, Plano, TX 75075\\n听说新团队...\n",
       "tag_list              北美刘一手,达拉斯火锅,达拉斯美食,达拉斯生活,达拉斯,达拉斯刘一手,达拉斯探店,达拉斯周边...\n",
       "image_count                                                          15\n",
       "content_type_video                                                    0\n",
       "hot_note                                                              1\n",
       "post_time                                           2024-10-31 00:58:04\n",
       "last_update_time                                    2024-10-31 12:52:24\n",
       "scraped_time                                        2025-03-12 00:55:08\n",
       "elapsed_time                                                        131\n",
       "liked_count                                                          93\n",
       "collected_count                                                      34\n",
       "comment_count                                                        66\n",
       "share_count                                                          64\n",
       "interaction_count                                                   193\n",
       "text                  【达拉斯·吃】刘一手，目前火锅届性价比天花板 📍2001 Coit Rd Ste 137D,...\n",
       "Name: 11, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice the 1st row of cont\n",
    "cont.iloc[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e7090e",
   "metadata": {},
   "source": [
    "中文文本清洗黄金四步法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731d2327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullwidth_to_halfwidth(text:str) -> str:\n",
    "    \"\"\"全角转半角（保留￥符号）\"\"\"\n",
    "    translation_table = str.maketrans({\n",
    "        '！': '!', '“': '\"', '”': '\"', '‘': \"'\", '’': \"'\",\n",
    "        '、': ',', '，': ',', '；': ';', '：': ':', '？': '?',\n",
    "        '《': '<', '》': '>', '【': '[', '】': ']', '·': '.',\n",
    "        '～': '~', '—': '-', '（': '(', '）': ')', '　': ' '\n",
    "    })\n",
    "    return text.translate(translation_table)\n",
    "\n",
    "def normalize_punctuation(text:str) -> str:\n",
    "    \"\"\"符号标准化（保留emoji, retain 字符的位置信息但牺牲了效率, 之后可以考虑优化\"\"\"\n",
    "    # 定义保留符号集（新增%$￥）\n",
    "    keep_symbols = {\"'\", '\"', ',', '.', ':', ';', '!', '?', '-', \n",
    "                   '(', ')', '<', '>', '[', ']', '&', '#', '@',\n",
    "                   '%', '$', '￥', '/', '=', '+', '~', '^'}\n",
    "    \n",
    "    # 字符级处理, \n",
    "    cleaned_chars = []\n",
    "    for char in text:\n",
    "        # 保留条件：字母数字/汉字/keep_symbols/emoji\n",
    "        if (char.isalnum() or\n",
    "            '\\u4e00' <= char <= '\\u9fff' or\n",
    "            char in keep_symbols or\n",
    "            emoji.is_emoji(char)):\n",
    "            cleaned_chars.append(char)\n",
    "        else:\n",
    "            cleaned_chars.append(' ')\n",
    "    \n",
    "    return ''.join(cleaned_chars)\n",
    "\n",
    "def remove_urls(text:str) -> str:\n",
    "    \"\"\"适配中文域名的URL移除\"\"\"\n",
    "    url_pattern = re.compile(\n",
    "        r'(?:https?://)?(?:[a-zA-Z0-9\\u4e00-\\u9fff-]+\\.)+[a-zA-Z]{2,}'\n",
    "        r'(?:/\\S*)?(?:\\?\\S*)?(?:#\\S*)?',\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "    return url_pattern.sub('', text)\n",
    "\n",
    "def basic_clean(\n",
    "        text : str\n",
    "    ) -> str:\n",
    "    \"\"\"\n",
    "    对文本进行基础层清洗，包括去除HTML标签、URL、特殊符号处理, 空格标准化等。\n",
    "    1. 移除HTML标签\n",
    "    2. 移除URL（适配中文域名）\n",
    "    3. 处理特殊符号（保留常用符号和emoji, 全角标点转半角）\n",
    "    4. 标准化空白字符\n",
    "\n",
    "    Args:\n",
    "        text (str): 待清洗的文本。\n",
    "    Returns:\n",
    "        str: 清洗后的文本。\n",
    "    \"\"\"\n",
    "    # 替换所有空白符（含小红书常见的全角空格\\u3000、换行、制表符）\n",
    "    text = re.sub(r'[\\t\\n\\u3000]', ' ', text)\n",
    "    # HTML标签移除\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    # URL移除, 适配中文域名\n",
    "    text = remove_urls(text)\n",
    "    # 全角转半角（保留全角￥）\n",
    "    text = fullwidth_to_halfwidth(text)\n",
    "    # 符号标准化\n",
    "    text = normalize_punctuation(text)\n",
    "    # 标准化合并连续空格\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "587d3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the basic_clean function to the 'text' column\n",
    "cont['text'] = cont['text'].apply(basic_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bd2225c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[达拉斯.吃]快乐小羊,回到儿时澳门豆捞坊 Happy Lamb Hot Pot 📍 240 Legacy Dr ste 116, Plano, TX 75023 感谢快乐小羊的邀请 虽然不知道小羊快不快乐[笑哭R]但我吃的很快乐 特别喜欢小羊家环境,舒适低调不喧哗,适合朋友聊天 所有菜品自取,更自由快捷,绝大多数都很新鲜(只有个别鹌鹑蛋黄不知为何有点咸鸭蛋味道,也许是我敏感[害羞R])我们选的金汤酸辣锅和特制香辣锅 金汤锅其实更像酸菜锅,酸菜味挺浓,还有很麻的口感,下了鱼片和牛肉,秒变酸菜鱼和酸菜牛 香辣锅是台湾健康感麻辣小火锅味儿,相对重庆火锅更为清淡,也更能体现食材本身的味道 强烈推荐他家臻品羊肉片,肥瘦合适还有奶香味 然后手打羊肉丸,和香菜混合制作,特别好吃 台湾酸甜口包心菜泡菜永远吃不腻 作为碳水大户,炒饭炒面炸馒头炸麻球完全满足了我的需求,炸鸡翅和橙子也很不错,小朋友饭应有尽有~ 重点来了!小羊给的两杯鸡尾酒把不太喝酒的我给惊艳了!图10中矮的那杯清冽的酒精带着丝丝甜味,醇香口感干脆利落,会一直想喝不停 有柠檬片的那杯是一种混合果汁配着清淡酸奶泡的无酒精鸡尾酒,打败我爱的所有果汁 没想到小羊要靠鸡尾酒出道了[笑哭R] 一顿饭下来,不仅吃的满足,整个氛围也让人想起童年回忆里的澳门豆捞坊,干净惬意有情调 我就喜欢这样安安静静享受火锅的快乐 #达拉斯火锅[话题]# #达拉斯美食[话题]# #达拉斯生活[话题]# #达拉斯[话题]# #达拉斯探店[话题]# #达拉斯周边[话题]# #达拉斯周末[话题]# #达拉斯吃喝玩乐[话题]# #快乐小羊[话题]# #快乐小羊火锅[话题]#'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont['text'][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d81f2",
   "metadata": {},
   "source": [
    "社交媒体特征处理层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77ee13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'有没有和我一样【吃茶三千】一喝一个不吱声的 连地址都不想写了 虽然环境还不错，颜值也不错 但我感觉自己完全拔草了 尝了mango茶sample：仿佛化掉的芒果冰棍 冻顶乌龙：茶味白开水 又见柠檬挞：矮子里的将军，青柠汁绿茶+cream，虽然算清新派里能喝的，但依旧偏寡淡 松针厚奶：茶香精味重+依旧白开水 \\t 是今天员工问题？还是达拉斯这家店问题？还是吃茶三千就这个风格？为什么值得排这么久的队呢…想不通啊想不通～'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def social_media_clean(text:str) -> str:\n",
    "    \"\"\"\n",
    "    社交媒体文本清洗，主要针对小红书平台的特定格式和符号进行处理。\n",
    "    1. 移除话题标签（#）但保留关键词\n",
    "    2. 移除@提及\n",
    "    3. 转换表情符号（可选：移除或转换为文本描述）\n",
    "    4. 处理小红书特有格式（如[笑哭R]）\n",
    "    5. 去除多余空格\n",
    "\n",
    "    Args:\n",
    "        text (str): 待清洗的文本。\n",
    "    Returns:\n",
    "        str: 清洗后的文本。\n",
    "    \"\"\"\n",
    "\n",
    "    # 移除话题标签但保留关键词（如 #达拉斯美食 → 达拉斯美食）\n",
    "    text = re.sub(r'#([^\\s#]+)', r'\\1', text)\n",
    "    \n",
    "    # 移除@提及(包含其变体, 如@小红书用户)\n",
    "    text = re.sub(r'@[\\w\\u4e00-\\u9fff-]+', '', text)  # 支持中英文用户名\n",
    "    \n",
    "    # 转换表情符号（可选策略）\n",
    "    strategy = 'remove'  # 或 'demojize'\n",
    "    if strategy == 'remove':\n",
    "        text = emoji.replace_emoji(text, replace='')\n",
    "    else:\n",
    "        text = emoji.demojize(text, delimiters=(' [', '] '))\n",
    "    \n",
    "    # 处理小红书特有格式（如[笑哭R]）\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460cdd92",
   "metadata": {},
   "source": [
    "中文英文混合语言环境优化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51188ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langid import classify\n",
    "import jieba\n",
    "\n",
    "def language_optimize(text):\n",
    "    # 语言检测（防止意外混入其他语言）\n",
    "    lang, confidence = classify(text)\n",
    "    if lang != 'zh' and confidence > 0.8:\n",
    "        return ''  # 或标记为需人工审核\n",
    "        \n",
    "    # 中英文混合处理（保留有效英文术语）\n",
    "    protected_terms = {'VIP', 'CEO', 'AI', 'NFT'}  # 自定义保护词表\n",
    "    words = jieba.lcut(text)\n",
    "    cleaned = []\n",
    "    for word in words:\n",
    "        if word.isalpha() and word.upper() not in protected_terms:\n",
    "            # 非保护英文词转小写（可选）\n",
    "            word = word.lower()  \n",
    "        cleaned.append(word)\n",
    "    \n",
    "    return ' '.join(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b737d34d",
   "metadata": {},
   "source": [
    "高级语义清洗层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d5c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def semantic_clean(texts, ngram_range=(1,2), max_df=0.95, min_df=3):\n",
    "    \"\"\"\n",
    "    基于TF-IDF的语义级清洗（需全量数据）\n",
    "    \"\"\"\n",
    "    tfidf = TfidfVectorizer(ngram_range=ngram_range, \n",
    "                          max_df=max_df, \n",
    "                          min_df=min_df)\n",
    "    matrix = tfidf.fit_transform(texts)\n",
    "    \n",
    "    # 识别高频无意义词（需自定义阈值）\n",
    "    df = pd.DataFrame(matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
    "    term_freq = df.sum(axis=0)\n",
    "    noise_terms = term_freq[term_freq > 500].index.tolist()  # 示例阈值\n",
    "    \n",
    "    # 构建正则过滤模式\n",
    "    pattern = r'\\b(?:{})\\b'.format('|'.join(noise_terms))\n",
    "    return [re.sub(pattern, '', text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f175e156",
   "metadata": {},
   "source": [
    "全流程集成示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4609cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSanitizer:\n",
    "    def __init__(self):\n",
    "        self.emoji_dict = emoji.EMOJI_DATA  # 预加载表情符号库\n",
    "        self.protected_terms = self._load_protected_terms()\n",
    "        \n",
    "    def _load_protected_terms(self):\n",
    "        # 从文件/数据库加载保护词表（品牌词、产品词等）\n",
    "        return {'鲜芋仙', 'MeetFresh', 'ParkPavilion'}  \n",
    "    \n",
    "    def pipeline(self, text):\n",
    "        text = basic_clean(text)\n",
    "        text = social_media_clean(text)\n",
    "        text = language_optimize(text)\n",
    "        return text\n",
    "    \n",
    "    def batch_process(self, texts):\n",
    "        # 并行加速（利用全部CPU核心）\n",
    "        from concurrent.futures import ProcessPoolExecutor\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            return list(executor.map(self.pipeline, texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8edcf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "性能优化策略. 正则表达式预编译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe58547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在类初始化时预编译正则表达式\n",
    "class TextSanitizer:\n",
    "    def __init__(self):\n",
    "        self.url_pattern = re.compile(r'(https?://\\S+)')\n",
    "        self.mention_pattern = re.compile(r'@\\w+')\n",
    "        # ...其他正则预编译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e6e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "性能优化策略 多语言混合处理增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加语言自动转换模块（需安装googletrans==4.0.0-rc1）\n",
    "from googletrans import Translator\n",
    "\n",
    "def translate_mixed_text(text):\n",
    "    translator = Translator()\n",
    "    chunks = []\n",
    "    current_lang = 'zh'\n",
    "    \n",
    "    for sentence in re.split(r'([.!?]+\\s*)', text):\n",
    "        if not sentence.strip():\n",
    "            continue\n",
    "        detected = translator.detect(sentence).lang\n",
    "        if detected != current_lang:\n",
    "            translated = translator.translate(sentence, src=detected, dest='zh').text\n",
    "            chunks.append(translated)\n",
    "        else:\n",
    "            chunks.append(sentence)\n",
    "    \n",
    "    return ''.join(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835966b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "性能优化策略 领域自适应清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0892c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载领域关键词白名单（餐饮类）\n",
    "DOMAIN_KEYWORDS = set()\n",
    "with open('food_terms.txt', encoding='utf-8') as f:\n",
    "    DOMAIN_KEYWORDS.update(line.strip() for line in f)\n",
    "\n",
    "def domain_aware_clean(text):\n",
    "    words = jieba.lcut(text)\n",
    "    return ' '.join([w for w in words if w in DOMAIN_KEYWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd958e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "质量评估指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced959a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clean_quality(original, cleaned):\n",
    "    # 信息保留率\n",
    "    orig_terms = set(jieba.lcut(original))\n",
    "    cleaned_terms = set(jieba.lcut(cleaned))\n",
    "    retention_rate = len(cleaned_terms & orig_terms) / len(orig_terms)\n",
    "    \n",
    "    # 噪声去除率\n",
    "    noise_removal = 1 - (len(cleaned)/len(original))\n",
    "    \n",
    "    # 可读性评分（基于平均句长）\n",
    "    sentences = re.split(r'[。！？]', cleaned)\n",
    "    avg_len = sum(len(s) for s in sentences)/len(sentences)\n",
    "    \n",
    "    return {\n",
    "        'retention': round(retention_rate, 3),\n",
    "        'noise_removal': round(noise_removal, 3),\n",
    "        'readability': 'good' if 15 < avg_len < 50 else 'poor'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f9d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable jieba , and use the accurate mode \n",
    "jieba.enable_paddle()\n",
    "jieba.set_dictionary('..\\..\\Data\\processed\\dict.txt.big')\n",
    "jieba.initialize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
