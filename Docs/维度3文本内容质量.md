### 文本内容评分细则

---

#### 一、核心要素与权重  
| 要素                  | 权重 | 指标构成                     | 理论依据                   | 数据来源          |  
|-----------------------|------|------------------------------|----------------------------|-------------------|  
| **文本原创性**        | 30%  | 内部重复度 + 语义相似度检测  | TF-IDF/SimCSE双轨验证模型  | 抓取笔记文本      |  
| **垂直领域分布**      | 20%  | 美食探店领域匹配度（余弦相似度）| 内容垂直性理论    | 领域标签数据库    |  
| **情感强度**          | 20%  | 时间衰减动态模型             | BERT情感量化理论       | 抓取笔记文本      |  
| **关键词覆盖**        | 20%  | 核心词命中率 + 长尾词密度    | 搜索优化理论       | 关键词热度库      |  
| **文字表达力**        | 10%  | 语义连贯性（跨段落）         | BERT-wwm-ext语义分析模型   | 抓取笔记文本      |  
*注1:为了避免过度参数化, 放弃考察语法规范性, 全网查重机制, 文本结构逻辑性.* 

*注2:因为只收集了文本, 所以没有考察笔记中的图片还有视频相关内容的考察.*

*注3:垂直领域分类：美食/时尚/美妆/出行/影视/家居/健康/娱乐/科技数码/人文/生活记录/潮流/母婴/职场/知识/情感* 

*注4:关键词规范化：采用TF-IDF归一化处理，消除超长尾词干扰*

---

#### 二、指标定义与计算逻辑  
**1. 文本原创性（30%）**  
*双阶段查重机制*：  
- **第一阶段（粗筛）**：Jieba分词+TF-IDF余弦相似度计算，检测博主历史笔记重复率
- **第二阶段（精筛）**：SimCSE语义向量比对（paraphrase-multilingual-MiniLM-L12-v2模型），识别洗稿内容  
```math  
\text{得分} = \left(1 - \max(\text{TF-IDF相似度}, \text{SimCSE相似度})\right) \times 30  
```  

**2. 垂直领域分布（20%）**  
*领域匹配算法*：  
- 基于预训练领域分类模型（ResNet-152架构）输出18类概率分布  
- 计算与美食探店领域标签的余弦相似度（阈值=0.9）  
```math  
\text{得分} = \frac{\text{领域相似度}}{0.9} \times 20  
```  

**3. 情感强度（20%）**  
*纯时间衰减模型*：  
- 采用指数衰减函数：$d_i = e^{-0.05t/7}$（$t$=距离发帖天数）  
- 动态加权各段落情感值（BERT-wwm-ext原始输出$s_i$-1至1经过线性映射到[0,1] ）
- *基准值*：采用动态基准值 $B_{Sent} = P_{90}$, where $ P_{90}$基于全量历史笔记的90%分位数动态调整阈值   
```math  
\text{强度} = \left(\sum_{i=1}^n \frac{s_i+1}{2} \times e^{-0.05t_i/7}\right) \times \frac{1}{B_{Sent}} \times 20  
```  

**4. 关键词覆盖（20%）**  
*分层检测机制*：  
- **核心词**：品牌/产品关键词命中率（权重60%）  
- **长尾词**：行业相关词密度（每千字≥8个，权重40%）  
```math  
\text{得分} = \left(\frac{\text{核心词命中数}}{5} \times 0.6 + \frac{\text{长尾词密度}}{8} \times 0.4\right) \times 20  
```  

**5. 文字表达力（10%）**  
*语义连贯性优化*：  
- *基准值*：采用动态基准值 $B_{Synt} = \max(0.68, P_{90})$, where $ P_{90}$基于全量历史笔记的90%分位数动态调整阈值  
```math  
\text{得分} = \frac{\text{语义相似度均值}}{B_{Synt}} \times 10  
```  

---

#### 三、技术部署方案  
**1. 数据处理架构**  
| 模块           | 技术实现                                                                 | 性能指标                  | 数据来源          |  
|----------------|--------------------------------------------------------------------------|---------------------------|-------------------|  
| **领域分类**   | ResNet-152+自定义分类头（PyTorch 2.2）                                  | 分类准确率≥92%   | 领域标签数据库    |  
| **分词处理**   | Jieba精确模式+垂直领域词典（加载1800+专业术语）                         | 未登录词比例≤1.8%   | 本地词库          |  
| **情感计算**   | BERT-wwm-ext量化模型（FP16精度优化）                                    | 推理速度≥120篇/秒     | HuggingFace模型库 |  

**2. 硬件配置**  
- **推理服务器**：NVIDIA H100（80GB显存）+ AMD EPYC 9754（128核）  
- **存储系统**：Ceph分布式集群（支持千万级历史笔记库实时检索）  
- **冷数据处理**：Apache Arrow列式存储（压缩率≥65%）  

**3. 软件依赖**  
```requirements.txt
jieba==0.42.1                # 中文分词核心库
sentence-transformers==2.6.1  # 语义相似度计算
torch==2.2.0                  # 领域分类模型框架
transformers==4.39.3          # BERT量化推理
```

---

#### 四、参考文献  
1. **He K, et al. Deep Residual Learning for Image Recognition** (CVPR 2016) - ResNet架构基础  
2. **《垂直领域内容匹配算法白皮书》**（中国人工智能学会, 2024） - 领域分类模型原理  
3. **Devlin J, et al. BERT: Pre-training of Deep Bidirectional Transformers** (NAACL 2019) - 情感分析基础  
4. **《中文搜索优化技术指南》**（百度搜索研究院, 2023） - 关键词分层策略  

---

