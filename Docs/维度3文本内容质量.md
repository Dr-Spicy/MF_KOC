### 文本内容评分细则

---

#### 一、核心要素与权重  
| 要素                  | 权重 | 指标构成                     | 理论依据                   | 数据来源          |  
|-----------------------|------|------------------------------|----------------------------|-------------------|  
| **文本原创性**        | 25%  | 内部多样性 + 外部原创性  | TF-IDF/SimCSE双轨验证模型  | 抓取笔记文本      |  
| **垂直领域分布**      | 25%  | 美食探店领域匹配度| 内容垂直性理论    | 领域标签数据库    |  
| **情感强度**          | 25%  | 动态时间衰减情感强度模型             | BERT情感量化理论       | 抓取笔记文本      |  
| **关键词覆盖**        | 25%  | 核心词命中率 + 时间衰减    | 搜索优化理论       | 关键词热度库      |  

*注1:为了避免过度参数化, 放弃考察语法规范性, 全网查重机制, 文本结构逻辑性.* 

*注2:因为只收集了文本, 所以没有考察笔记中的图片还有视频相关内容的考察.*

*注3:混合语境文本处理模块 (XHS Mixed Language Processor)*

    - 专为处理小红书平台上的中英混合文本而设计的class, XHSMixedLanguageProcessor，其流程包括:               
        # 1. 基础清洗(去除HTML标签、URL、特殊符号等, 全角转半角, 空格标准化)
        text = self.basic_clean(text)

        # 2. 社交媒体特定清洗 (去除话题标签、@提及、Emoji的demojize, 处理小红书特定标签和表情包)
        text = self.social_media_clean(text)

        # 3. 中英语境优化（用langid做语言检测, 对批量处理超过100条且文本中文含量低于50%时用deep_translator API翻译）
        if enable_translation and is_batch_large:
            text = self.language_optimize(text, protected_terms=self.protected_terms)

        # 4. 语义筛选 (jieba中文分词, 根据TF-IDF去除噪声词, 并保护领域关键词）
        text = self.chinese_semantic_clean([text])[0]


---

#### 二、指标定义与计算逻辑  
**A. 文本原创性（25%）**  
*目的概述*:

- 评估创作者内容的独特性和原创度，识别能够持续产出差异化高质量内容的创作者
- 通过内外部双维度原创性评估机制，使用两种语义相似度算法确保评估的准确性和鲁棒性, 同时考察创作者自身内容的多样性和与其他创作者内容的差异性

*双维度原创性评估机制*：  
- **内部多样性（权重50%）**：
    - 使用Jieba分词+TF-IDF向量化(max_features=8000)计算创作者所有笔记之间的文本相似度
    - 应用SimCSE语义向量模型（paraphrase-multilingual-MiniLM-L12-v2）计算内容语义相似度
    - 对于笔记数量少于20篇的创作者，采用默认多样性分数0.8
    - 结合两种相似度计算方法：`内部多样性 = 1 - (0.5 * TF-IDF平均相似度 + 0.5 * SimCSE平均相似度)`
- **外部原创性（权重50%）**：
    - 基于创作者代表性内容（包括最新发布的10篇笔记和所有热门笔记）
    - 若最新加热门笔记不够,再加上最新的未选取笔记补足100篇
    - 使用SimCSE模型计算不同创作者之间的内容相似度
    - 综合考虑平均相似度和最大相似度：`外部原创性 = 1 - (0.6 * 平均相似度 + 0.4 * 最大相似度)` 
- **分数计算公式**:
```math  
\text{原始分数} = 0.5 \times \text{内部多样性} + 0.5 \times \text{外部原创性}
```  
- **非线性映射与分布校正**:
*使用以Sigmoid为基础的函数将原始分数一对一映射到0-25区间且标准差不低于4.0, 并对极端分数做出软化处理*:
```math  
\text{原创性得分} = \frac{25}{1 + e^{-8 \times (\text{原始分数} - 0.4)}}
``` 

**B. 垂直领域分布（25%）**  
*目的概述*:

- 评估创作者在特定垂直领域的专业专注度，识别和奖励对目标领域持续输出高质量内容的创作者。
- 通过标签匹配的方式，计算每个创作者笔记中与垂直领域相关标签的覆盖率，并使用非线性转换映射到评分区间。

*领域匹配算法*：  
- 核心机制：基于创作者笔记中包含目标标签子字符串的笔记数量比例进行评分
- 目标标签集：{'美食', '探店', '火锅', '甜品', '奶茶', '外卖', '中餐', '小吃', 'food'}
- 匹配方式：采用子字符串模式匹配，不区分大小写和格式
- 笔记覆盖率：计算每位创作者的笔记中包含目标标签的比例, $\text{标签覆盖率} = \frac{\text{包含目标标签的笔记数}}{\text{总笔记数}}$, 并用幂函数优化低分区间的区分 

- **分数计算公式**:
```math  
\text{原始分数} = (\text{标签覆盖率})^{0.7} \times 25
```  
- **非线性映射与分布校正**:
*使用以Sigmoid为基础的函数将原始分数一对一映射到0-25区间且标准差不低于4.0, 并对极端分数做出软化处理*:
```math
\text{垂直领域得分} = \frac{25}{1 + e^{-5 \times (\text{原始分数} - 0.4)}}
```

**C. 情感强度（25%）**  
*目的概述*：

- 评估创作者表达情感的强度和倾向，识别能够传递丰富情感体验的内容创作者
- 通过深度学习情感分析模型，量化笔记文本中的情感极性和强度，并融合时间衰减机制

*情感分析算法*： 

- 核心机制:
    - 基于BERT预训练模型(uer/roberta-base-finetuned-jd-binary-chinese)进行自然语言情感分析
    - 对每位创作者最多处理100篇笔记，优先选择最新和热门内容
    - 结合多维情感特征，包括情感均值、情感绝对强度、极值和波动性

- 情感特征提取:
    - 情感极性均值：笔记情感值的算术平均，反映总体情感倾向
    - 情感强度：基于情感值绝对值的平均，表示情感表达力度
    - 情感极值：记录最高正向情感和最强负向情感
    - 情感波动：计算不同笔记间情感值的标准差

- 时间衰减模型：
    - 采用指数时间衰减函数：$d_i = e^{-0.05t/7}$（$t$=发布距今天数）

- **分数计算公式**: 
```math  
\text{原始情感特征} = 0.3 \times \text{情感均值} + 0.3 \times \text{情感强度} + 0.2 \times \text{正向极值} + 0.2 \times |\text{负向极值}| 
```  

- **非线性映射与分布校正**:
*使用以Sigmoid为基础的函数将原始分数一对一映射到0-25区间且标准差不低于4.0, 并对极端分数做出软化处理*:
```math
\text{情感得分} = \frac{25}{1 + e^{-3 \times (\text{原始情感特征} - 0.2)}}
```


**D. 关键词覆盖（25%）**  
*目的概述*：

- 评估创作者笔记中对核心关键词的覆盖程度，识别高度相关且持续产出目标品牌内容的创作者
- 通过品牌/产品核心词的检测与时间衰减机制，平衡关键词覆盖率与发布时效性

*关键词检测算法*： 

- 核心机制:
    - 基于正则表达式匹配技术识别文本中的核心关键词出现频次
    - 结合时间衰减模型，对最新内容给予更高权重
    - 综合考察单篇笔记的关键词密度和整体笔记的关键词覆盖率

- 关键词匹配策略:
    - 目标关键词集：鲜芋仙、MeetFresh、台湾美食、甜品、芋圆、taro、仙草等28个核心词
    - 匹配方式：不区分大小写的子字符串匹配，支持中英文混合
    - 笔记覆盖率：计算每位创作者含有至少1个关键词的笔记比例

- 时间衰减模型：
    - 采用指数时间衰减函数：$d_i = e^{-0.05t/7}$（$t$=发布距今天数）

```math  

\text{单篇笔记得分} = \max(1, \frac{\text{关键词数量}}{5}) \times \text{时间衰减系数}
```
```math
\text{标准化分数} = \frac{0.7 \times \text{平均笔记得分} + 0.3 \times (\frac{\text{关键词覆盖率}}{0.05})}{2} - 0.2
```
- **非线性映射与分布校正**:
*使用以Sigmoid为基础的函数将原始分数一对一映射到0-25区间且标准差不低于4.0, 并对极端分数做出软化处理*:
```math
\text{关键词得分} = \frac{25}{1 + e^{-3 \times (\text{标准化分数} - 0.4)}}
```



---

#### **三、案例验证**  
| 账号类型       | 原创性 | 领域匹配 | 情感强度 | 关键词覆盖 | 总分  | 数据特征                   |  
|----------------|--------|----------|----------|------------|-------|----------------------------|  
| 火锅探店达人   | 20.3   | 22.1     | 19.8     | 21.5       | 83.7  | 核心词"鲜芋仙"全匹配        |  
| 烘焙教程博主   | 18.7   | 19.4     | 17.2     | 18.9       | 74.2  | 领域匹配度0.78（阈值0.85） |  

---
#### 四、参考文献  
1. **He K, et al. Deep Residual Learning for Image Recognition** (CVPR 2016) - ResNet架构基础  
2. **《垂直领域内容匹配算法白皮书》**（中国人工智能学会, 2024） - 领域分类模型原理  
3. **Devlin J, et al. BERT: Pre-training of Deep Bidirectional Transformers** (NAACL 2019) - 情感分析基础  
4. **《中文搜索优化技术指南》**（百度搜索研究院, 2023） - 关键词分层策略  

---
